{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(numberOfSamples): #quite quick\n",
    "    plt.figure\n",
    "    labelList = []\n",
    "    dataList = []\n",
    "\n",
    "    with open('train.csv', newline='') as csvfile:\n",
    "\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        fieldnames = None\n",
    "        label = None\n",
    "        for i, row in enumerate(reader):\n",
    "            if fieldnames is None:\n",
    "                fieldnames = [x for x in reader.fieldnames if x != 'label']\n",
    "                #print(fieldnames)\n",
    "\n",
    "\n",
    "            label_val = row.pop('label')\n",
    "            labelList.append(label_val)#store label\n",
    "            #print('label_val :',label_val)\n",
    "            pixels = [row[x] for x in fieldnames]\n",
    "            array = np.array(pixels,dtype=np.uint8)\n",
    "            array = array.reshape((IMG_WIDTH,IMG_HEIGHT))\n",
    "            #store data\n",
    "            dataList.append(array)\n",
    "            #plotting\n",
    "            #fig = plt.figure(i,figsize = [1,1])\n",
    "            #ax = fig.add_axes([1,1,1,1])\n",
    "            #ax.imshow(array)\n",
    "            #ax.set_title(label_val,fontsize=20)\n",
    "            \n",
    "            if(i>=numberOfSamples-1):\n",
    "                break\n",
    "    return(labelList,dataList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayData(label, data,colNum = 40): #is a bit long to compute\n",
    "    strLen = str(len(label))\n",
    "    rowNum = ceil((len(label)/int(colNum)))\n",
    "    subplot = rowNum+colNum\n",
    "    fig, axs = plt.subplots(rowNum, colNum, figsize = [20,2.3])\n",
    "    row = 0\n",
    "    col = 0\n",
    "    for i in range(len(label)):\n",
    "        axs[row, col].imshow(data[i])\n",
    "        axs[row, col].axis('off')\n",
    "        axs[row, col].set_title(label[i])\n",
    "        if (col < colNum-1):\n",
    "            col += 1\n",
    "        else:\n",
    "            col = 0\n",
    "            row += 1\n",
    "    for i in range(len(label),len(label)+(colNum - len(label)%colNum)):\n",
    "\n",
    "        axs[row, col].axis('off')\n",
    "        if (col < colNum-1):\n",
    "            col += 1\n",
    "        else:\n",
    "            col = 0\n",
    "            row += 1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv('./train.csv')\n",
    "#test = pd.read_csv('./test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "trainDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showImage(df, index):\n",
    "    #image = df.iloc[index]\n",
    "    image = trainDF.iloc[index][1:].values.reshape(28,28)\n",
    "    plt.imshow(image,cmap='Greys')\n",
    "    plt.title(trainDF['label'].iloc[index])\n",
    "showImage(trainDF, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nan values \n",
    "trainDF.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{The dataset is clean}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{Define the function useful in our model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the rectified linear unit function\n",
    "relu = lambda x: (x+abs(x))/2\n",
    "\n",
    "#convolve(data, kernel)\n",
    "def convolution_layer(image, filt):\n",
    "    temp = convolve(image, filt)\n",
    "    filtered = relu(temp)\n",
    "    return (temp, filtered)\n",
    "\n",
    "def convolved(image,kernel):\n",
    "    return(convolve(image,kernel))\n",
    "\n",
    "def maxPooling(image, size = 2):#problem with layer limits\n",
    "    res = skimage.measure.block_reduce(image, (size,size), np.max)\n",
    "    return(res)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x)\n",
    "    return (e_x / sum(e_x))\n",
    "\n",
    "def lossFunc(x, label):#categorical cross entropy loss (softmax + cross entropy)\n",
    "    return (-np.sum(label * np.log(x)))\n",
    "\n",
    "\n",
    "\n",
    "def convolution(image, filt, bias, s=1):\n",
    "    '''\n",
    "    Confolves `filt` over `image` using stride `s`\n",
    "    '''\n",
    "    (n_f, n_c_f, f, _) = filt.shape # filter dimensions\n",
    "    n_c, in_dim, _ = image.shape # image dimensions\n",
    "    \n",
    "    out_dim = int((in_dim - f)/s)+1 # calculate output dimensions\n",
    "    \n",
    "    # ensure that the filter dimensions match the dimensions of the input image\n",
    "    assert n_c == n_c_f, \"Dimensions of filter must match dimensions of input image\"\n",
    "    \n",
    "    out = np.zeros((n_f,out_dim,out_dim)) # create the matrix to hold the values of the convolution operation\n",
    "    \n",
    "    # convolve each filter over the image\n",
    "    for curr_f in range(n_f):\n",
    "        curr_y = out_y = 0\n",
    "        # move filter vertically across the image\n",
    "        while curr_y + f <= in_dim:\n",
    "            curr_x = out_x = 0\n",
    "            # move filter horizontally across the image \n",
    "            while curr_x + f <= in_dim:\n",
    "                # perform the convolution operation and add the bias\n",
    "                out[curr_f, out_y, out_x] = np.sum(filt[curr_f] * image[:,curr_y:curr_y+f, curr_x:curr_x+f]) + bias[curr_f]\n",
    "                curr_x += s\n",
    "                out_x += 1\n",
    "            curr_y += s\n",
    "            out_y += 1\n",
    "        \n",
    "    return out\n",
    "\n",
    "def maxpool(image, f=2, s=2):\n",
    "    '''\n",
    "    Downsample input `image` using a kernel size of `f` and a stride of `s`\n",
    "    '''\n",
    "    n_c, h_prev, w_prev = image.shape\n",
    "    \n",
    "    # calculate output dimensions after the maxpooling operation.\n",
    "    h = int((h_prev - f)/s)+1 \n",
    "    w = int((w_prev - f)/s)+1\n",
    "    \n",
    "    # create a matrix to hold the values of the maxpooling operation.\n",
    "    downsampled = np.zeros((n_c, h, w)) \n",
    "    \n",
    "    # slide the window over every part of the image using stride s. Take the maximum value at each step.\n",
    "    for i in range(n_c):\n",
    "        curr_y = out_y = 0\n",
    "        # slide the max pooling window vertically across the image\n",
    "        while curr_y + f <= h_prev:\n",
    "            curr_x = out_x = 0\n",
    "            # slide the max pooling window horizontally across the image\n",
    "            while curr_x + f <= w_prev:\n",
    "                # choose the maximum value within the window at each step and store it to the output matrix\n",
    "                downsampled[i, out_y, out_x] = np.max(image[i, curr_y:curr_y+f, curr_x:curr_x+f])\n",
    "                curr_x += s\n",
    "                out_x += 1\n",
    "            curr_y += s\n",
    "            out_y += 1\n",
    "    return downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeFilter(size, scale = 1.0):\n",
    "    '''\n",
    "    Initialize filter using a normal distribution with and a \n",
    "    standard deviation inversely proportional the square root of the number of units\n",
    "    '''\n",
    "    stddev = scale/np.sqrt(np.prod(size))\n",
    "    return np.random.normal(loc = 0, scale = stddev, size = size)\n",
    "\n",
    "def initializeWeight(size):\n",
    "    '''\n",
    "    Initialize weights with a random normal distribution\n",
    "    '''\n",
    "    return np.random.standard_normal(size=size) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  $\\text{Define backward }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted and modified from https://towardsdatascience.com/convolutional-neural-networks-from-the-ground-up-c67bb41454e1\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s):\n",
    "    '''\n",
    "    Backpropagation through a convolutional layer. \n",
    "    '''\n",
    "    (n_f, n_c, f, _) = filt.shape\n",
    "    (_, orig_dim, _) = conv_in.shape\n",
    "    ## initialize derivatives\n",
    "    dout = np.zeros(conv_in.shape) \n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dbias = np.zeros((n_f,1))\n",
    "    for curr_f in range(n_f):\n",
    "        # loop through all filters\n",
    "        curr_y = out_y = 0\n",
    "        while curr_y + f <= orig_dim:\n",
    "            curr_x = out_x = 0\n",
    "            while curr_x + f <= orig_dim:\n",
    "                # loss gradient of filter (used to update the filter)\n",
    "                dfilt[curr_f] += dconv_prev[curr_f, out_y, out_x] * conv_in[:, curr_y:curr_y+f, curr_x:curr_x+f]\n",
    "                # loss gradient of the input to the convolution operation (conv1 in the case of this network)\n",
    "                dout[:, curr_y:curr_y+f, curr_x:curr_x+f] += dconv_prev[curr_f, out_y, out_x] * filt[curr_f] \n",
    "                curr_x += s\n",
    "                out_x += 1\n",
    "            curr_y += s\n",
    "            out_y += 1\n",
    "        # loss gradient of the bias\n",
    "        dbias[curr_f] = np.sum(dconv_prev[curr_f])\n",
    "    \n",
    "    return dout, dfilt, dbias\n",
    "\n",
    "\n",
    "def maxpoolBackward(dpool, orig, f = 2, s = 2):\n",
    "    '''\n",
    "    Backpropagation through a maxpooling layer. The gradients are passed through the indices of greatest value in the original maxpooling during the forward step.\n",
    "    '''\n",
    "    (n_c, orig_dim, _) = orig.shape\n",
    "    \n",
    "    dout = np.zeros(orig.shape)\n",
    "    \n",
    "    for curr_c in range(n_c):\n",
    "        curr_y = out_y = 0\n",
    "        while curr_y + f <= orig_dim:\n",
    "            curr_x = out_x = 0\n",
    "            while curr_x + f <= orig_dim:\n",
    "                # obtain index of largest value in input for current window\n",
    "                arr = orig[curr_c, curr_y:curr_y+f, curr_x:curr_x+f]\n",
    "                (a, b) = np.unravel_index(np.nanargmax(arr), arr.shape)\n",
    "                dout[curr_c, curr_y+a, curr_x+b] = dpool[curr_c, out_y, out_x]\n",
    "                \n",
    "                curr_x += s\n",
    "                out_x += 1\n",
    "            curr_y += s\n",
    "            out_y += 1\n",
    "        \n",
    "    return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{Forward + backward}$\n",
    "\n",
    "$\\text{}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted and modified from https://towardsdatascience.com/convolutional-neural-networks-from-the-ground-up-c67bb41454e1\n",
    "#modified\n",
    "def conv(image, label, params, conv_s, pool_f, pool_s):\n",
    "    \n",
    "    [f1, f2, w1, w2, b1, b2, b3, b4] = params \n",
    "    \n",
    "    ################################################\n",
    "    ############## Forward Operation ###############\n",
    "    ################################################\n",
    "    #convolve + relu first one\n",
    "    conv1 = convolution(image, f1, b1, conv_s)#convolve(image, f1)\n",
    "    conv1 = relu(conv1)\n",
    "\n",
    "    pooled1 = maxpool(conv1, pool_f, pool_s)\n",
    "    (nf2, dim2, _) = pooled1.shape\n",
    "    flatpool1 = pooled1.reshape((nf2 * dim2 * dim2, 1)) # flatten pooled layer\n",
    "\n",
    "     #convolve + relu second one\n",
    "    conv2 = convolution(pooled1, f2, b2, conv_s)#convolve(conv1, f1)\n",
    "    conv2 = relu(conv2)\n",
    "\n",
    "    pooled2 = maxpool(conv2, pool_f, pool_s)#maxPooling(conv2, size = 2)#pool_f, pool_s ???\n",
    "\n",
    "    (nf2, dim2, _) = pooled2.shape\n",
    "    flatpool2 = pooled2.reshape((nf2 * dim2 * dim2, 1)) # flatten pooled layer\n",
    "\n",
    "    hidden = relu(w1.dot(flatpool2) + b3) # first dense layer + relu\n",
    "\n",
    "    out = w2.dot(hidden) + b4 # second dense layer\n",
    "\n",
    "    probs = softmax(out) # predict class probabilities with the softmax activation function\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    #################### Loss ######################\n",
    "    ################################################\n",
    "    loss = 0\n",
    "    loss = lossFunc(probs, label) # categorical cross-entropy loss\n",
    "\n",
    "    ################################################\n",
    "    ############# Backward Operation ###############\n",
    "    ################################################\n",
    "    #NN -> pool2 -> conv2 -> pool1 -> conv1\n",
    "    dout = probs - label # derivative of loss w.r.t. final dense layer output\n",
    "    dw2 = dout.dot(hidden.T) # loss gradient of final dense layer weights\n",
    "    db4 = np.sum(dout, axis = 1).reshape(b4.shape) # loss gradient of final dense layer biases\n",
    "\n",
    "    dhidden = relu(w2.T.dot(dout)) # loss gradient of first dense layer outputs + relu\n",
    "\n",
    "    dw1 = dhidden.dot(flatpool2.T)\n",
    "    db3 = np.sum(dhidden, axis = 1).reshape(b3.shape)\n",
    "\n",
    "    dfc2 = w1.T.dot(dhidden) # loss gradients of fully-connected layer (pooling layer)\n",
    "    dpool2 = dfc2.reshape(pooled2.shape) # reshape fully connected into dimensions of pooling layer\n",
    "\n",
    "    dconv2 = maxpoolBackward(dpool2, conv2, pool_f, pool_s) # backprop through the max-pooling layer(only neurons with highest activation in window get updated)\n",
    "    dconv2 = relu(dconv2) # backpropagate through ReLU\n",
    "\n",
    "    #---que rajoute-t-on ici ?????????????\n",
    "    dpool1, df2, db2 = convolutionBackward(dconv2, pooled1, f2, conv_s)\n",
    "    #dpool1= relu(dpool1) # backpropagate through ReLU ->not necessary ?????????\n",
    "    #dpool1, df1,df3 = #??convolutionBackward(dconv2, pooled1, f2, conv_s)\n",
    "    #dpool2 = dfc.reshape(pooled.shape)\n",
    "\n",
    "    dconv1 = maxpoolBackward(dpool1, conv1, pool_f, pool_s) \n",
    "    dconv1= relu(dconv1) # backpropagate through ReLU\n",
    "\n",
    "    dimage, df1, db1 = convolutionBackward(dconv1, image, f1, conv_s) # backpropagate previous gradient through first convolutional layer.\n",
    "\n",
    "    grads = [df1, df2, dw1, dw2, db1, db2, db3, db4] \n",
    "    \n",
    "    return grads, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i will try another thing before (a more classic approach ?)\n",
    "def adamGD(batch, num_classes, lr, dim, n_c, beta1, beta2, params, cost):\n",
    "    '''\n",
    "    update the parameters through Adam gradient descnet.\n",
    "    '''\n",
    "    [f1, f2, w3, w4, b1, b2, b3, b4] = params\n",
    "    \n",
    "    X = batch[:,0:-1] # get batch inputs\n",
    "    #print(type(batch),type(dim),type(n_c))\n",
    "    #print('dim',dim,type(dim))\n",
    "    X = X.reshape(len(batch), n_c, dim, dim)\n",
    "    Y = batch[:,-1] # get batch labels\n",
    "    \n",
    "    cost_ = 0\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # initialize gradients and momentum,RMS params\n",
    "    df1 = np.zeros(f1.shape)\n",
    "    df2 = np.zeros(f2.shape)\n",
    "    dw3 = np.zeros(w3.shape)\n",
    "    dw4 = np.zeros(w4.shape)\n",
    "    db1 = np.zeros(b1.shape)\n",
    "    db2 = np.zeros(b2.shape)\n",
    "    db3 = np.zeros(b3.shape)\n",
    "    db4 = np.zeros(b4.shape)\n",
    "    \n",
    "    v1 = np.zeros(f1.shape)\n",
    "    v2 = np.zeros(f2.shape)\n",
    "    v3 = np.zeros(w3.shape)\n",
    "    v4 = np.zeros(w4.shape)\n",
    "    bv1 = np.zeros(b1.shape)\n",
    "    bv2 = np.zeros(b2.shape)\n",
    "    bv3 = np.zeros(b3.shape)\n",
    "    bv4 = np.zeros(b4.shape)\n",
    "    \n",
    "    s1 = np.zeros(f1.shape)\n",
    "    s2 = np.zeros(f2.shape)\n",
    "    s3 = np.zeros(w3.shape)\n",
    "    s4 = np.zeros(w4.shape)\n",
    "    bs1 = np.zeros(b1.shape)\n",
    "    bs2 = np.zeros(b2.shape)\n",
    "    bs3 = np.zeros(b3.shape)\n",
    "    bs4 = np.zeros(b4.shape)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        x = X[i]\n",
    "        y = np.eye(num_classes)[int(Y[i])].reshape(num_classes, 1) # convert label to one-hot\n",
    "        \n",
    "        # Collect Gradients for training example\n",
    "        grads, loss = conv(x, y, params, 1, 2, 2)\n",
    "        [df1_, df2_, dw3_, dw4_, db1_, db2_, db3_, db4_] = grads\n",
    "        \n",
    "        df1+=df1_\n",
    "        db1+=db1_\n",
    "        df2+=df2_\n",
    "        db2+=db2_\n",
    "        dw3+=dw3_\n",
    "        db3+=db3_\n",
    "        dw4+=dw4_\n",
    "        db4+=db4_\n",
    "\n",
    "        cost_+= loss\n",
    "\n",
    "    # Parameter Update  \n",
    "        \n",
    "    v1 = beta1*v1 + (1-beta1)*df1/batch_size # momentum update\n",
    "    s1 = beta2*s1 + (1-beta2)*(df1/batch_size)**2 # RMSProp update\n",
    "    f1 -= lr * v1/np.sqrt(s1+1e-7) # combine momentum and RMSProp to perform update with Adam\n",
    "    \n",
    "    bv1 = beta1*bv1 + (1-beta1)*db1/batch_size\n",
    "    bs1 = beta2*bs1 + (1-beta2)*(db1/batch_size)**2\n",
    "    b1 -= lr * bv1/np.sqrt(bs1+1e-7)\n",
    "   \n",
    "    v2 = beta1*v2 + (1-beta1)*df2/batch_size\n",
    "    s2 = beta2*s2 + (1-beta2)*(df2/batch_size)**2\n",
    "    f2 -= lr * v2/np.sqrt(s2+1e-7)\n",
    "                       \n",
    "    bv2 = beta1*bv2 + (1-beta1) * db2/batch_size\n",
    "    bs2 = beta2*bs2 + (1-beta2)*(db2/batch_size)**2\n",
    "    b2 -= lr * bv2/np.sqrt(bs2+1e-7)\n",
    "    \n",
    "    v3 = beta1*v3 + (1-beta1) * dw3/batch_size\n",
    "    s3 = beta2*s3 + (1-beta2)*(dw3/batch_size)**2\n",
    "    w3 -= lr * v3/np.sqrt(s3+1e-7)\n",
    "    \n",
    "    bv3 = beta1*bv3 + (1-beta1) * db3/batch_size\n",
    "    bs3 = beta2*bs3 + (1-beta2)*(db3/batch_size)**2\n",
    "    b3 -= lr * bv3/np.sqrt(bs3+1e-7)\n",
    "    \n",
    "    v4 = beta1*v4 + (1-beta1) * dw4/batch_size\n",
    "    s4 = beta2*s4 + (1-beta2)*(dw4/batch_size)**2\n",
    "    w4 -= lr * v4 / np.sqrt(s4+1e-7)\n",
    "    \n",
    "    bv4 = beta1*bv4 + (1-beta1)*db4/batch_size\n",
    "    bs4 = beta2*bs4 + (1-beta2)*(db4/batch_size)**2\n",
    "    b4 -= lr * bv4 / np.sqrt(bs4+1e-7)\n",
    "    \n",
    "    \n",
    "    cost_ = cost_/batch_size\n",
    "    cost.append(cost_)\n",
    "\n",
    "    params = [f1, f2, w3, w4, b1, b2, b3, b4]\n",
    "    \n",
    "    return params, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, params, num_classes = 10, lr = 0.01, beta1 = 0.95,\n",
    "          beta2 = 0.99, img_dim = 28, img_depth = 1, f = 5, num_filt1 = 8,\n",
    "          num_filt2 = 8, batch_size = 32, num_epochs = 2):\n",
    "\n",
    "    \n",
    "    np.random.shuffle(train_data)#shuffle the training data\n",
    "\n",
    "    cost = []\n",
    "\n",
    "    print(\"LR:\"+str(lr)+\", Batch Size:\"+str(batch_size))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(train_data)\n",
    "        batches = [train_data[k:k + batch_size] for k in range(0, train_data.shape[0], batch_size)]\n",
    "\n",
    "        t = tqdm(batches)\n",
    "        for x,batch in enumerate(t):\n",
    "            params, cost = adamGD(batch, num_classes, lr, img_dim, img_depth, beta1, beta2, params, cost)\n",
    "            t.set_description(\"Cost: %.2f\" % (cost[-1]))\n",
    "            \n",
    "    final_params = params\n",
    "    \n",
    "    return final_params, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out_neurons = trainDF['label'].nunique()\n",
    "def initialize(X, y,num_filt1 = 8, img_depth = 1, f=5, num_filt2 = 8, num_hidden_neurons = 128):\n",
    "    #w1 = (num hiden neuron, num input neurons)\n",
    "    #w2 = (num out neuron, num hiden neuron)\n",
    "    f1, f2, w1, w2 = (num_filt1 ,img_depth,f,f), (num_filt2 ,num_filt1,f,f), (num_hidden_neurons,128), (num_out_neurons, num_hidden_neurons)\n",
    "    f1 = initializeFilter(f1)\n",
    "    f2 = initializeFilter(f2)\n",
    "    w1 = initializeWeight(w1)\n",
    "    w2 = initializeWeight(w2)\n",
    "    \n",
    "    b1 = np.zeros((f1.shape[0],1))\n",
    "    b2 = np.zeros((f2.shape[0],1))\n",
    "    b3 = np.zeros((w1.shape[0],1))\n",
    "    b4 = np.zeros((w2.shape[0],1))\n",
    "\n",
    "    params = [f1, f2, w1, w2, b1, b2, b3, b4]\n",
    "\n",
    "    #prepare the training data\n",
    "    y_dash = y_train.reshape(len(y_train),1)\n",
    "    \n",
    "    #print(np.shape(y_dash),np.shape(X))\n",
    "    train_data = np.hstack((X,y_dash))\n",
    "    \n",
    "    return (train_data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainDF['label'].values\n",
    "x_train = trainDF.drop(columns = ['label'])\n",
    "#x_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72.3 ms, sys: 76 ms, total: 148 ms\n",
      "Wall time: 147 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Initialize the parameters\n",
    "train_data, params = initialize(x_train,y_train)#initialize on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\underline{\\textbf{Model Training}}$\n",
    "\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:0.01, Batch Size:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cost: 2.31:   6%|â–Œ         | 73/1313 [13:33<4:02:14, 11.72s/it]"
     ]
    }
   ],
   "source": [
    "#train\n",
    "final_params, cost = train(train_data = train_data, params = params, num_classes = trainDF['label'].nunique(),\n",
    "                           lr = 0.01, beta1 = 0.95, beta2 = 0.99,\n",
    "                           img_dim = 28, img_depth = 1, f = 5, num_filt1 = 8,\n",
    "                           num_filt2 = 8, batch_size = 32, num_epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
